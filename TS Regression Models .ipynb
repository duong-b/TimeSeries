{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIME SERIES REGRESSION MODELS \n",
    "\n",
    "## Selecting predictors \n",
    "\n",
    "Practices that are **not recommended** when selecting predictors \n",
    "    \n",
    "    1. Plot the forecast variable against a particular predictor and drop the variable if there is no noticeable reslationship\n",
    "    2. Do multiple regression and eliminate the ones with small p-values\n",
    "   \n",
    "Both of the mentioned above do not account for effects of predictors on each other. \n",
    "    \n",
    "Instead, we will use a measure of predictive accuracy. \n",
    "    \n",
    "## Predictive Accuracy Measures\n",
    "There are 5 measures of predictive accuracy:\n",
    "    \n",
    "    1. Adjusted $R^2$\n",
    "    \n",
    "    2. Cross-validation\n",
    "    \n",
    "    3. Akaike's Information Criterion\n",
    "    \n",
    "    4. Corrected Akaike's Information Criterion \n",
    "    \n",
    "    5. Schwarz's Bayesian Information Criterion \n",
    "\n",
    "\n",
    "### Adjusted $R^2$\n",
    "\n",
    "$R^2$: coefficient of determination. \n",
    "Rule: The higher $R^2$, the better. \n",
    "\n",
    "The adjusted-$R^2$ is to help curb the following disadvantages of using $R^2$\n",
    "\n",
    "1. $R^2$ tells us how well the regression model fits the data, _not_ how well it'll predict the future data. \n",
    "2. $R^2$ does not allow for \"degree of freedom\". Adding _any_ variable tends to increase the value of $R^2$ \n",
    "\n",
    "The adjusted-$R^2$ is calculated by: \n",
    "\n",
    "$$Adjusted-R^2 = 1-(1-R^2)\\frac{T-1}{T-k-1}$$\n",
    "\n",
    "where: \n",
    "\n",
    "$T$: the number of observations \n",
    "\n",
    "$k$: the number of predictors\n",
    "\n",
    "--> Adjusted-$R^2$ tends to include too many predictor variables\n",
    "\n",
    "### Cross-validation : Leave-one-out cross-validation\n",
    "\n",
    "Procedures: \n",
    "1. Remove an observation $t$ (eg. $t=1$) from the dataset, and fit the model using the remaining data. \n",
    "2. Compute the error for observation $t$: $e_t^ = y_t - \\hat{y_t}$\n",
    "3. Repeat the above steps for each of other observations $t=2, \\dots, T$\n",
    "4. Compute MSE (mean-squared errors) from $e_1, \\dots, e_t$\n",
    "\n",
    "$$ CV=MSE = \\frac{1}{T} \\sum_{t=1}^T (e_t)^2 $$\n",
    "\n",
    "Rule: the smaller CV, the better the model. \n",
    "\n",
    "### Akaike's Information Criterion (AIC)\n",
    "\n",
    "$$ AIC = T \\ln \\left( \\frac{SSE}{T} \\right) + 2(k+2)$$ \n",
    "\n",
    "where: \n",
    "\n",
    "$T$: the number of observations \n",
    "\n",
    "$k$: the number of predictors \n",
    "\n",
    "$SSE = sum of squared errors = \\sum_{t = 1}^T e_t^2$\n",
    "\n",
    "$k+2$ refers to $k$ coefficients for the predictors, the intercept, and the variance of the residuals. \n",
    "\n",
    "Rule: the smaller AIC, the better the model for forecasting\n",
    "\n",
    "### Corrected Akaike's Information Criterion \n",
    "\n",
    "This measure is to correct the issue of choosing too many predictors when $T$ is small. \n",
    "\n",
    "$$ AIC_c = AIC + \\frac{2(k+2)(k+3)}{T-k-3}$$\n",
    "\n",
    "Rule: same as AIC\n",
    "\n",
    "### Schwarz's Bayesian Information Criterion (BIC)\n",
    "\n",
    "$$BIC = T\\ln \\left( \\frac{SSE}{T} \\right) + (k+2)\\ln(T)$$\n",
    "\n",
    "Rule: The smaller the BIC value, the better the model. \n",
    "\n",
    "**NOTE:** AIC models and BIC penalize the fit of the model (SSE) with the number of parameters, but BIC does it more heavily than AICs. If the value of $T$ is large enough, they all lead to the same model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
